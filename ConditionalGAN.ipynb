{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P84NVYcgQhcZ"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_token = {\"username\":\"username\",\"key\":\"key\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)"
      ],
      "metadata": {
        "id": "2rGPGpAFQrNr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g450W-nQyBj",
        "outputId": "27bec231-2739-473b-f60c-b8a00ff641d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading brain-tumor-mri-dataset.zip to /content\n",
            "100% 148M/149M [00:08<00:00, 23.5MB/s]\n",
            "100% 149M/149M [00:08<00:00, 18.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq brain-tumor-mri-dataset.zip"
      ],
      "metadata": {
        "id": "365KoSilQ2qb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "dAolJO0rQ4tN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.set_random_seed(1234)"
      ],
      "metadata": {
        "id": "R6XCgLXMQ6pd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagePaths = \"Training\""
      ],
      "metadata": {
        "id": "0WwcOHD0Q8oR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testPaths = \"Testing\""
      ],
      "metadata": {
        "id": "8y0NLfsESZLm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "img_height = 128\n",
        "img_width = 128  "
      ],
      "metadata": {
        "id": "W7d5bmSqRCUY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  imagePaths,\n",
        "  color_mode='grayscale',\n",
        "  #validation_split=0.0,\n",
        "  #subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Yl1_gcRFgf",
        "outputId": "e8d93cdf-4122-43ed-be11-096eab53a539"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5712 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  testPaths,\n",
        "  color_mode='grayscale',\n",
        "  #validation_split=0.0,\n",
        "  #subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX6sbNXCSchk",
        "outputId": "5a99b1c9-9f60-4b2f-8abe-43eb45990676"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1311 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= tf.concat([x for x, y in train_ds], axis=0)\n",
        "y_train= tf.concat([y for x, y in train_ds], axis=0)\n",
        "x_test= tf.concat([x for x, y in test_ds], axis=0)\n",
        "y_test= tf.concat([y for x, y in test_ds], axis=0)"
      ],
      "metadata": {
        "id": "I0XbutJ2SSJM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "KzKADpyoTDbg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "yB5-u4L2TJaC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "RHnzexMaTK3E"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_digits = np.concatenate([x_train, x_test])\n",
        "all_labels = np.concatenate([y_train, y_test])\n",
        "\n",
        "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
        "# the images, and one-hot encode the labels.\n",
        "all_digits = all_digits.astype(\"float32\") / 255.0\n",
        "all_digits = np.reshape(all_digits, (-1, 128, 128, 1))\n",
        "all_labels = keras.utils.to_categorical(all_labels, 4)\n",
        "\n",
        "# Create tf.data.Dataset.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "print(f\"Shape of training images: {all_digits.shape}\")\n",
        "print(f\"Shape of training labels: {all_labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLeilgCqS7ho",
        "outputId": "5adbc259-8a37-47b8-e7ab-cdfda077fec0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training images: (7023, 128, 128, 1)\n",
            "Shape of training labels: (7023, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiLKrW8JRHyA",
        "outputId": "e1cd25a1-c703-4b8d-afb2-dcccf91a7934"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow_docs.vis import embed\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio"
      ],
      "metadata": {
        "id": "UuSBbQe_RSqO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_channels = 1\n",
        "num_classes = 4\n",
        "image_size = 128\n",
        "latent_dim = 128"
      ],
      "metadata": {
        "id": "rM1omS1pRWcW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_in_channels = latent_dim + num_classes\n",
        "discriminator_in_channels = num_channels + num_classes\n",
        "print(generator_in_channels, discriminator_in_channels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWzPt0-tRZVx",
        "outputId": "c30f5757-7d04-404d-80ad-d2c6f5d5037b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the discriminator.\n",
        "inp= tf.keras.Input(shape=(128, 128, discriminator_in_channels))\n",
        "x = layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\")(inp)\n",
        "x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "x = layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
        "x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "x = layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
        "x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "x = layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
        "x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "x = layers.GlobalMaxPooling2D()(x)\n",
        "out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "  \n",
        "discriminator= tf.keras.Model(inputs=inp, outputs=out)"
      ],
      "metadata": {
        "id": "_T-nGozcmiNp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = tf.keras.Input(shape=(generator_in_channels,))\n",
        "# We want to generate 128 + num_classes coefficients to reshape into a\n",
        "# 7x7x(128 + num_classes) map.\n",
        "x = layers.Dense(8 * 8 * generator_in_channels)(inp)\n",
        "x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "x = layers.Reshape((8, 8, generator_in_channels))(x)\n",
        "x = layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\")(x)\n",
        "x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "x = layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding=\"same\")(x)\n",
        "x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "x = layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding=\"same\")(x)\n",
        "x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "x = layers.Conv2DTranspose(16, (4, 4), strides=(2, 2), padding=\"same\")(x)\n",
        "x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "out = layers.Conv2D(1, (8, 8), padding=\"same\", activation=\"tanh\")(x)\n",
        "generator = tf.keras.Model(inputs=inp, outputs=out)"
      ],
      "metadata": {
        "id": "tOqrJWhmRg8J"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalGAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
        "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data.\n",
        "        real_images, one_hot_labels = data\n",
        "\n",
        "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
        "        # the images. This is for the discriminator.\n",
        "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
        "        image_one_hot_labels = tf.repeat(\n",
        "            image_one_hot_labels, repeats=[image_size * image_size]\n",
        "        )\n",
        "        image_one_hot_labels = tf.reshape(\n",
        "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space and concatenate the labels.\n",
        "        # This is for the generator.\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        random_vector_labels = tf.concat(\n",
        "            [random_latent_vectors, one_hot_labels], axis=1\n",
        "        )\n",
        "\n",
        "        # Decode the noise (guided by labels) to fake images.\n",
        "        generated_images = self.generator(random_vector_labels)\n",
        "\n",
        "        # Combine them with real images. Note that we are concatenating the labels\n",
        "        # with these images here.\n",
        "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
        "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
        "        combined_images = tf.concat(\n",
        "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
        "        )\n",
        "\n",
        "        # Assemble labels discriminating real from fake images.\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "\n",
        "        # Train the discriminator.\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space.\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        random_vector_labels = tf.concat(\n",
        "            [random_latent_vectors, one_hot_labels], axis=1\n",
        "        )\n",
        "\n",
        "        # Assemble labels that say \"all real images\".\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_images = self.generator(random_vector_labels)\n",
        "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
        "            predictions = self.discriminator(fake_image_and_labels)\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Monitor loss.\n",
        "        self.gen_loss_tracker.update_state(g_loss)\n",
        "        self.disc_loss_tracker.update_state(d_loss)\n",
        "        return {\n",
        "            \"g_loss\": self.gen_loss_tracker.result(),\n",
        "            \"d_loss\": self.disc_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "eBJFl6f2RmhF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond_gan = ConditionalGAN(\n",
        "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
        ")\n",
        "cond_gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")"
      ],
      "metadata": {
        "id": "owRQfy6LRp7t"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond_gan.fit(dataset, epochs=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t1AVt4ZR97b",
        "outputId": "4c0f2c04-b931-4616-e3c1-b12d5cd820cb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5676: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 26s 98ms/step - g_loss: 1.3811 - d_loss: 0.6004\n",
            "Epoch 2/600\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.2406 - d_loss: 0.7137\n",
            "Epoch 3/600\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 3.4005 - d_loss: 0.1584\n",
            "Epoch 4/600\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 3.7777 - d_loss: 0.1822\n",
            "Epoch 5/600\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 6.7638 - d_loss: 9.6278e-04\n",
            "Epoch 6/600\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 7.4970 - d_loss: 4.5801e-04\n",
            "Epoch 7/600\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 7.8793 - d_loss: 0.0105\n",
            "Epoch 8/600\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 2.9529 - d_loss: 0.7663\n",
            "Epoch 9/600\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 3.8037 - d_loss: 0.2064\n",
            "Epoch 10/600\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 6.1747 - d_loss: 0.2683\n",
            "Epoch 11/600\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.0439 - d_loss: 0.5001\n",
            "Epoch 12/600\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 0.9384 - d_loss: 0.6015\n",
            "Epoch 13/600\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.2063 - d_loss: 0.6096\n",
            "Epoch 14/600\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.7320 - d_loss: 0.5158\n",
            "Epoch 15/600\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.8238 - d_loss: 0.4127\n",
            "Epoch 16/600\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.7300 - d_loss: 0.3831\n",
            "Epoch 17/600\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 2.0778 - d_loss: 0.4191\n",
            "Epoch 18/600\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.3275 - d_loss: 0.5619\n",
            "Epoch 19/600\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4881 - d_loss: 0.5386\n",
            "Epoch 20/600\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.1259 - d_loss: 0.5585\n",
            "Epoch 21/600\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.3014 - d_loss: 0.5914\n",
            "Epoch 22/600\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.1824 - d_loss: 0.5179\n",
            "Epoch 23/600\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.3138 - d_loss: 0.4899\n",
            "Epoch 24/600\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.2097 - d_loss: 0.5598\n",
            "Epoch 25/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.8234 - d_loss: 0.3687\n",
            "Epoch 26/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.3198 - d_loss: 0.5310\n",
            "Epoch 27/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.2028 - d_loss: 0.4962\n",
            "Epoch 28/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.1608 - d_loss: 0.5152\n",
            "Epoch 29/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.2820 - d_loss: 0.4540\n",
            "Epoch 30/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.2321 - d_loss: 0.4624\n",
            "Epoch 31/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.3504 - d_loss: 0.4038\n",
            "Epoch 32/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.3540 - d_loss: 0.4355\n",
            "Epoch 33/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.2901 - d_loss: 0.4900\n",
            "Epoch 34/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6271 - d_loss: 0.4334\n",
            "Epoch 35/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.1869 - d_loss: 0.5215\n",
            "Epoch 36/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.2439 - d_loss: 0.4910\n",
            "Epoch 37/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.2817 - d_loss: 0.4833\n",
            "Epoch 38/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.1620 - d_loss: 0.5275\n",
            "Epoch 39/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.2598 - d_loss: 0.4990\n",
            "Epoch 40/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.2901 - d_loss: 0.5003\n",
            "Epoch 41/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.1463 - d_loss: 0.5106\n",
            "Epoch 42/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.0991 - d_loss: 0.5246\n",
            "Epoch 43/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9884 - d_loss: 0.6136\n",
            "Epoch 44/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9762 - d_loss: 0.5919\n",
            "Epoch 45/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9401 - d_loss: 0.6097\n",
            "Epoch 46/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9431 - d_loss: 0.6060\n",
            "Epoch 47/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.2442 - d_loss: 0.6241\n",
            "Epoch 48/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8725 - d_loss: 0.6239\n",
            "Epoch 49/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9760 - d_loss: 0.6313\n",
            "Epoch 50/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8985 - d_loss: 0.6603\n",
            "Epoch 51/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8744 - d_loss: 0.6170\n",
            "Epoch 52/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8549 - d_loss: 0.6248\n",
            "Epoch 53/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8652 - d_loss: 0.6419\n",
            "Epoch 54/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9159 - d_loss: 0.6683\n",
            "Epoch 55/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8894 - d_loss: 0.6251\n",
            "Epoch 56/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8241 - d_loss: 0.6377\n",
            "Epoch 57/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8828 - d_loss: 0.6527\n",
            "Epoch 58/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9194 - d_loss: 0.6322\n",
            "Epoch 59/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9070 - d_loss: 0.6229\n",
            "Epoch 60/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9292 - d_loss: 0.6823\n",
            "Epoch 61/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9687 - d_loss: 0.6170\n",
            "Epoch 62/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9614 - d_loss: 0.6317\n",
            "Epoch 63/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9189 - d_loss: 0.6181\n",
            "Epoch 64/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.0487 - d_loss: 0.6256\n",
            "Epoch 65/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.9635 - d_loss: 0.5472\n",
            "Epoch 66/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 3.2786 - d_loss: 0.1706\n",
            "Epoch 67/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.3986 - d_loss: 0.4755\n",
            "Epoch 68/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.1296 - d_loss: 0.5337\n",
            "Epoch 69/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.1054 - d_loss: 0.5602\n",
            "Epoch 70/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9928 - d_loss: 0.6138\n",
            "Epoch 71/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9733 - d_loss: 0.5688\n",
            "Epoch 72/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.2167 - d_loss: 0.7151\n",
            "Epoch 73/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9045 - d_loss: 0.6196\n",
            "Epoch 74/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9035 - d_loss: 0.6489\n",
            "Epoch 75/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8939 - d_loss: 0.6315\n",
            "Epoch 76/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9131 - d_loss: 0.6263\n",
            "Epoch 77/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8224 - d_loss: 0.6481\n",
            "Epoch 78/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9082 - d_loss: 0.6584\n",
            "Epoch 79/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8812 - d_loss: 0.6487\n",
            "Epoch 80/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.0056 - d_loss: 0.5890\n",
            "Epoch 81/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0508 - d_loss: 0.6134\n",
            "Epoch 82/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9121 - d_loss: 0.6318\n",
            "Epoch 83/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9618 - d_loss: 0.6186\n",
            "Epoch 84/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8745 - d_loss: 0.6357\n",
            "Epoch 85/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8225 - d_loss: 0.6635\n",
            "Epoch 86/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8459 - d_loss: 0.6439\n",
            "Epoch 87/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8876 - d_loss: 0.6303\n",
            "Epoch 88/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.0632 - d_loss: 0.6056\n",
            "Epoch 89/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8786 - d_loss: 0.6181\n",
            "Epoch 90/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8935 - d_loss: 0.6453\n",
            "Epoch 91/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9535 - d_loss: 0.6388\n",
            "Epoch 92/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8713 - d_loss: 0.6416\n",
            "Epoch 93/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8647 - d_loss: 0.6442\n",
            "Epoch 94/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9425 - d_loss: 0.6092\n",
            "Epoch 95/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8982 - d_loss: 0.6463\n",
            "Epoch 96/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9116 - d_loss: 0.6555\n",
            "Epoch 97/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8313 - d_loss: 0.6492\n",
            "Epoch 98/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8046 - d_loss: 0.6504\n",
            "Epoch 99/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8493 - d_loss: 0.6459\n",
            "Epoch 100/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9453 - d_loss: 0.6273\n",
            "Epoch 101/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8451 - d_loss: 0.6304\n",
            "Epoch 102/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8522 - d_loss: 0.6633\n",
            "Epoch 103/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8291 - d_loss: 0.6471\n",
            "Epoch 104/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9181 - d_loss: 0.6378\n",
            "Epoch 105/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8964 - d_loss: 0.6752\n",
            "Epoch 106/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6883 - d_loss: 0.5229\n",
            "Epoch 107/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9683 - d_loss: 0.6048\n",
            "Epoch 108/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9756 - d_loss: 0.5622\n",
            "Epoch 109/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8624 - d_loss: 0.6082\n",
            "Epoch 110/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8440 - d_loss: 0.6428\n",
            "Epoch 111/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8493 - d_loss: 0.6301\n",
            "Epoch 112/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9190 - d_loss: 0.6040\n",
            "Epoch 113/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8909 - d_loss: 0.6488\n",
            "Epoch 114/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9220 - d_loss: 0.6210\n",
            "Epoch 115/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8744 - d_loss: 0.6242\n",
            "Epoch 116/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9080 - d_loss: 0.6149\n",
            "Epoch 117/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8652 - d_loss: 0.6335\n",
            "Epoch 118/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8379 - d_loss: 0.6604\n",
            "Epoch 119/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1669 - d_loss: 0.5724\n",
            "Epoch 120/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0721 - d_loss: 0.6571\n",
            "Epoch 121/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8001 - d_loss: 0.7174\n",
            "Epoch 122/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.7577 - d_loss: 0.7567\n",
            "Epoch 123/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8259 - d_loss: 0.6746\n",
            "Epoch 124/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9658 - d_loss: 0.6268\n",
            "Epoch 125/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8488 - d_loss: 0.6638\n",
            "Epoch 126/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8128 - d_loss: 0.6739\n",
            "Epoch 127/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9354 - d_loss: 0.6778\n",
            "Epoch 128/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0572 - d_loss: 0.6886\n",
            "Epoch 129/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9000 - d_loss: 0.6226\n",
            "Epoch 130/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7892 - d_loss: 0.6795\n",
            "Epoch 131/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.7658 - d_loss: 0.6735\n",
            "Epoch 132/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8247 - d_loss: 0.6717\n",
            "Epoch 133/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7673 - d_loss: 0.6959\n",
            "Epoch 134/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8773 - d_loss: 0.6549\n",
            "Epoch 135/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8033 - d_loss: 0.6841\n",
            "Epoch 136/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7794 - d_loss: 0.6659\n",
            "Epoch 137/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.7810 - d_loss: 0.6911\n",
            "Epoch 138/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8035 - d_loss: 0.6648\n",
            "Epoch 139/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8011 - d_loss: 0.6744\n",
            "Epoch 140/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.7924 - d_loss: 0.6789\n",
            "Epoch 141/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8060 - d_loss: 0.6640\n",
            "Epoch 142/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8090 - d_loss: 0.6767\n",
            "Epoch 143/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7866 - d_loss: 0.6636\n",
            "Epoch 144/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7719 - d_loss: 0.6625\n",
            "Epoch 145/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7852 - d_loss: 0.6675\n",
            "Epoch 146/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8140 - d_loss: 0.7118\n",
            "Epoch 147/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8311 - d_loss: 0.6917\n",
            "Epoch 148/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1267 - d_loss: 0.5515\n",
            "Epoch 149/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9750 - d_loss: 0.5971\n",
            "Epoch 150/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8253 - d_loss: 0.6537\n",
            "Epoch 151/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7600 - d_loss: 0.7049\n",
            "Epoch 152/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7853 - d_loss: 0.6615\n",
            "Epoch 153/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9013 - d_loss: 0.6388\n",
            "Epoch 154/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7922 - d_loss: 0.6922\n",
            "Epoch 155/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8329 - d_loss: 0.6312\n",
            "Epoch 156/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8071 - d_loss: 0.6531\n",
            "Epoch 157/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9330 - d_loss: 0.6488\n",
            "Epoch 158/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0234 - d_loss: 0.6957\n",
            "Epoch 159/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0750 - d_loss: 0.6325\n",
            "Epoch 160/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8553 - d_loss: 0.6490\n",
            "Epoch 161/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8383 - d_loss: 0.6514\n",
            "Epoch 162/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8173 - d_loss: 0.6806\n",
            "Epoch 163/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8058 - d_loss: 0.6714\n",
            "Epoch 164/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0640 - d_loss: 0.5760\n",
            "Epoch 165/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8292 - d_loss: 0.6840\n",
            "Epoch 166/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8453 - d_loss: 0.6506\n",
            "Epoch 167/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8122 - d_loss: 0.6689\n",
            "Epoch 168/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0317 - d_loss: 0.6767\n",
            "Epoch 169/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7753 - d_loss: 0.6880\n",
            "Epoch 170/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7926 - d_loss: 0.6608\n",
            "Epoch 171/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7649 - d_loss: 0.6686\n",
            "Epoch 172/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7528 - d_loss: 0.6806\n",
            "Epoch 173/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7699 - d_loss: 0.6730\n",
            "Epoch 174/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8155 - d_loss: 0.6550\n",
            "Epoch 175/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.7942 - d_loss: 0.6684\n",
            "Epoch 176/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.7911 - d_loss: 0.6520\n",
            "Epoch 177/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8421 - d_loss: 0.6787\n",
            "Epoch 178/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8978 - d_loss: 0.6583\n",
            "Epoch 179/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.3780 - d_loss: 0.6272\n",
            "Epoch 180/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8606 - d_loss: 0.6399\n",
            "Epoch 181/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8116 - d_loss: 0.7104\n",
            "Epoch 182/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8490 - d_loss: 0.6395\n",
            "Epoch 183/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1645 - d_loss: 0.5514\n",
            "Epoch 184/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8167 - d_loss: 0.6731\n",
            "Epoch 185/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8664 - d_loss: 0.6343\n",
            "Epoch 186/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8464 - d_loss: 0.6393\n",
            "Epoch 187/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9456 - d_loss: 0.6715\n",
            "Epoch 188/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6746 - d_loss: 0.6081\n",
            "Epoch 189/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9942 - d_loss: 0.5867\n",
            "Epoch 190/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8560 - d_loss: 0.6432\n",
            "Epoch 191/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8131 - d_loss: 0.6492\n",
            "Epoch 192/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8110 - d_loss: 0.6384\n",
            "Epoch 193/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7898 - d_loss: 0.6580\n",
            "Epoch 194/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.7660 - d_loss: 0.6685\n",
            "Epoch 195/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.7715 - d_loss: 0.6600\n",
            "Epoch 196/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7784 - d_loss: 0.6593\n",
            "Epoch 197/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7817 - d_loss: 0.6627\n",
            "Epoch 198/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0130 - d_loss: 0.6426\n",
            "Epoch 199/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9389 - d_loss: 0.6322\n",
            "Epoch 200/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.7698 - d_loss: 0.6692\n",
            "Epoch 201/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8149 - d_loss: 0.6448\n",
            "Epoch 202/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8883 - d_loss: 0.6373\n",
            "Epoch 203/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9501 - d_loss: 0.6636\n",
            "Epoch 204/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8634 - d_loss: 0.6444\n",
            "Epoch 205/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8342 - d_loss: 0.6341\n",
            "Epoch 206/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8488 - d_loss: 0.6426\n",
            "Epoch 207/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9089 - d_loss: 0.6359\n",
            "Epoch 208/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7811 - d_loss: 0.7576\n",
            "Epoch 209/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.9186 - d_loss: 0.6982\n",
            "Epoch 210/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8083 - d_loss: 0.6631\n",
            "Epoch 211/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7649 - d_loss: 0.6799\n",
            "Epoch 212/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7699 - d_loss: 0.6746\n",
            "Epoch 213/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7484 - d_loss: 0.6706\n",
            "Epoch 214/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7629 - d_loss: 0.6732\n",
            "Epoch 215/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.7787 - d_loss: 0.6628\n",
            "Epoch 216/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7824 - d_loss: 0.6617\n",
            "Epoch 217/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7623 - d_loss: 0.6645\n",
            "Epoch 218/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7634 - d_loss: 0.6628\n",
            "Epoch 219/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7692 - d_loss: 0.6576\n",
            "Epoch 220/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0071 - d_loss: 0.6259\n",
            "Epoch 221/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8210 - d_loss: 0.6662\n",
            "Epoch 222/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8260 - d_loss: 0.6517\n",
            "Epoch 223/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9173 - d_loss: 0.6245\n",
            "Epoch 224/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8615 - d_loss: 0.6378\n",
            "Epoch 225/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8307 - d_loss: 0.6501\n",
            "Epoch 226/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6404 - d_loss: 0.5941\n",
            "Epoch 227/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8535 - d_loss: 0.6326\n",
            "Epoch 228/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.2098 - d_loss: 0.5805\n",
            "Epoch 229/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8211 - d_loss: 0.6483\n",
            "Epoch 230/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8198 - d_loss: 0.6327\n",
            "Epoch 231/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.7801 - d_loss: 0.6642\n",
            "Epoch 232/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8055 - d_loss: 0.6378\n",
            "Epoch 233/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8805 - d_loss: 0.6114\n",
            "Epoch 234/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8734 - d_loss: 0.6219\n",
            "Epoch 235/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8088 - d_loss: 0.6396\n",
            "Epoch 236/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8920 - d_loss: 0.6243\n",
            "Epoch 237/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8535 - d_loss: 0.6336\n",
            "Epoch 238/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8531 - d_loss: 0.6280\n",
            "Epoch 239/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8180 - d_loss: 0.6504\n",
            "Epoch 240/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8069 - d_loss: 0.6457\n",
            "Epoch 241/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8317 - d_loss: 0.6325\n",
            "Epoch 242/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8134 - d_loss: 0.6435\n",
            "Epoch 243/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 0.8341 - d_loss: 0.6301\n",
            "Epoch 244/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8622 - d_loss: 0.6318\n",
            "Epoch 245/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8883 - d_loss: 0.6107\n",
            "Epoch 246/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9409 - d_loss: 0.6189\n",
            "Epoch 247/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8507 - d_loss: 0.6290\n",
            "Epoch 248/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9214 - d_loss: 0.6496\n",
            "Epoch 249/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8084 - d_loss: 0.6548\n",
            "Epoch 250/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8619 - d_loss: 0.6351\n",
            "Epoch 251/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9311 - d_loss: 0.5792\n",
            "Epoch 252/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9020 - d_loss: 0.6416\n",
            "Epoch 253/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9098 - d_loss: 0.5985\n",
            "Epoch 254/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8580 - d_loss: 0.6213\n",
            "Epoch 255/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8538 - d_loss: 0.6088\n",
            "Epoch 256/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8575 - d_loss: 0.6112\n",
            "Epoch 257/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.8769 - d_loss: 0.6141\n",
            "Epoch 258/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9214 - d_loss: 0.5981\n",
            "Epoch 259/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8875 - d_loss: 0.6091\n",
            "Epoch 260/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8901 - d_loss: 0.6091\n",
            "Epoch 261/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9638 - d_loss: 0.5692\n",
            "Epoch 262/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.2959 - d_loss: 0.5662\n",
            "Epoch 263/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0160 - d_loss: 0.5517\n",
            "Epoch 264/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9631 - d_loss: 0.5805\n",
            "Epoch 265/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1922 - d_loss: 0.5698\n",
            "Epoch 266/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0006 - d_loss: 0.6846\n",
            "Epoch 267/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5904 - d_loss: 0.5425\n",
            "Epoch 268/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1833 - d_loss: 0.6226\n",
            "Epoch 269/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0112 - d_loss: 0.5450\n",
            "Epoch 270/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8844 - d_loss: 0.6002\n",
            "Epoch 271/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9095 - d_loss: 0.5843\n",
            "Epoch 272/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9117 - d_loss: 0.5710\n",
            "Epoch 273/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9506 - d_loss: 0.5725\n",
            "Epoch 274/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8900 - d_loss: 0.5843\n",
            "Epoch 275/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.8942 - d_loss: 0.5873\n",
            "Epoch 276/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9351 - d_loss: 0.5771\n",
            "Epoch 277/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9766 - d_loss: 0.5782\n",
            "Epoch 278/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9140 - d_loss: 0.5808\n",
            "Epoch 279/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9174 - d_loss: 0.5799\n",
            "Epoch 280/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9679 - d_loss: 0.5799\n",
            "Epoch 281/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9420 - d_loss: 0.5810\n",
            "Epoch 282/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9156 - d_loss: 0.5849\n",
            "Epoch 283/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9216 - d_loss: 0.5847\n",
            "Epoch 284/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9161 - d_loss: 0.5918\n",
            "Epoch 285/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9654 - d_loss: 0.5829\n",
            "Epoch 286/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0165 - d_loss: 0.5477\n",
            "Epoch 287/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9679 - d_loss: 0.5740\n",
            "Epoch 288/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0142 - d_loss: 0.5607\n",
            "Epoch 289/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9337 - d_loss: 0.5944\n",
            "Epoch 290/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 0.9788 - d_loss: 0.5605\n",
            "Epoch 291/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9873 - d_loss: 0.5730\n",
            "Epoch 292/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0406 - d_loss: 0.5742\n",
            "Epoch 293/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0241 - d_loss: 0.5617\n",
            "Epoch 294/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0377 - d_loss: 0.5604\n",
            "Epoch 295/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9966 - d_loss: 0.5616\n",
            "Epoch 296/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9932 - d_loss: 0.5493\n",
            "Epoch 297/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0258 - d_loss: 0.5695\n",
            "Epoch 298/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9857 - d_loss: 0.5674\n",
            "Epoch 299/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0525 - d_loss: 0.5501\n",
            "Epoch 300/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0179 - d_loss: 0.5509\n",
            "Epoch 301/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0044 - d_loss: 0.5564\n",
            "Epoch 302/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0369 - d_loss: 0.5457\n",
            "Epoch 303/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1154 - d_loss: 0.5436\n",
            "Epoch 304/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1079 - d_loss: 0.5280\n",
            "Epoch 305/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1187 - d_loss: 0.5311\n",
            "Epoch 306/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1152 - d_loss: 0.5600\n",
            "Epoch 307/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1155 - d_loss: 0.5610\n",
            "Epoch 308/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0604 - d_loss: 0.5707\n",
            "Epoch 309/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1685 - d_loss: 0.5117\n",
            "Epoch 310/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0945 - d_loss: 0.5468\n",
            "Epoch 311/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0975 - d_loss: 0.5570\n",
            "Epoch 312/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0595 - d_loss: 0.5589\n",
            "Epoch 313/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0381 - d_loss: 0.5575\n",
            "Epoch 314/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0567 - d_loss: 0.5498\n",
            "Epoch 315/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0826 - d_loss: 0.5514\n",
            "Epoch 316/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0666 - d_loss: 0.5457\n",
            "Epoch 317/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0239 - d_loss: 0.5466\n",
            "Epoch 318/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0898 - d_loss: 0.5605\n",
            "Epoch 319/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1222 - d_loss: 0.5630\n",
            "Epoch 320/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1597 - d_loss: 0.5305\n",
            "Epoch 321/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0853 - d_loss: 0.5441\n",
            "Epoch 322/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1109 - d_loss: 0.5314\n",
            "Epoch 323/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0216 - d_loss: 0.5768\n",
            "Epoch 324/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0734 - d_loss: 0.5266\n",
            "Epoch 325/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0390 - d_loss: 0.5614\n",
            "Epoch 326/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 0.9911 - d_loss: 0.5683\n",
            "Epoch 327/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0525 - d_loss: 0.5457\n",
            "Epoch 328/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0583 - d_loss: 0.5420\n",
            "Epoch 329/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0667 - d_loss: 0.5270\n",
            "Epoch 330/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0514 - d_loss: 0.5419\n",
            "Epoch 331/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1118 - d_loss: 0.5217\n",
            "Epoch 332/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0957 - d_loss: 0.5529\n",
            "Epoch 333/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0869 - d_loss: 0.5461\n",
            "Epoch 334/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1488 - d_loss: 0.5528\n",
            "Epoch 335/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1239 - d_loss: 0.5329\n",
            "Epoch 336/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.2154 - d_loss: 0.5308\n",
            "Epoch 337/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1101 - d_loss: 0.5440\n",
            "Epoch 338/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1080 - d_loss: 0.5548\n",
            "Epoch 339/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1892 - d_loss: 0.5392\n",
            "Epoch 340/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0941 - d_loss: 0.5508\n",
            "Epoch 341/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1292 - d_loss: 0.5424\n",
            "Epoch 342/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0979 - d_loss: 0.5274\n",
            "Epoch 343/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0697 - d_loss: 0.5206\n",
            "Epoch 344/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1529 - d_loss: 0.5319\n",
            "Epoch 345/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1629 - d_loss: 0.5239\n",
            "Epoch 346/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1237 - d_loss: 0.5489\n",
            "Epoch 347/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1578 - d_loss: 0.5361\n",
            "Epoch 348/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0737 - d_loss: 0.5456\n",
            "Epoch 349/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1280 - d_loss: 0.5260\n",
            "Epoch 350/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0666 - d_loss: 0.5358\n",
            "Epoch 351/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1273 - d_loss: 0.5234\n",
            "Epoch 352/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.2066 - d_loss: 0.5037\n",
            "Epoch 353/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1162 - d_loss: 0.5538\n",
            "Epoch 354/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1324 - d_loss: 0.5487\n",
            "Epoch 355/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.2638 - d_loss: 0.4903\n",
            "Epoch 356/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1571 - d_loss: 0.5111\n",
            "Epoch 357/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1296 - d_loss: 0.5304\n",
            "Epoch 358/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1052 - d_loss: 0.5251\n",
            "Epoch 359/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0311 - d_loss: 0.5532\n",
            "Epoch 360/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0859 - d_loss: 0.5525\n",
            "Epoch 361/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1291 - d_loss: 0.5300\n",
            "Epoch 362/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1408 - d_loss: 0.5277\n",
            "Epoch 363/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1750 - d_loss: 0.5160\n",
            "Epoch 364/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1587 - d_loss: 0.5370\n",
            "Epoch 365/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1343 - d_loss: 0.5366\n",
            "Epoch 366/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1488 - d_loss: 0.5269\n",
            "Epoch 367/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1584 - d_loss: 0.5755\n",
            "Epoch 368/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0722 - d_loss: 0.5512\n",
            "Epoch 369/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1673 - d_loss: 0.5242\n",
            "Epoch 370/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1481 - d_loss: 0.5194\n",
            "Epoch 371/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1062 - d_loss: 0.5333\n",
            "Epoch 372/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0649 - d_loss: 0.5283\n",
            "Epoch 373/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0898 - d_loss: 0.5439\n",
            "Epoch 374/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1003 - d_loss: 0.5462\n",
            "Epoch 375/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1284 - d_loss: 0.5492\n",
            "Epoch 376/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1331 - d_loss: 0.5364\n",
            "Epoch 377/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1171 - d_loss: 0.5081\n",
            "Epoch 378/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1169 - d_loss: 0.5206\n",
            "Epoch 379/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.2989 - d_loss: 0.5325\n",
            "Epoch 380/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1548 - d_loss: 0.5182\n",
            "Epoch 381/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.2360 - d_loss: 0.5378\n",
            "Epoch 382/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1869 - d_loss: 0.5139\n",
            "Epoch 383/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1231 - d_loss: 0.5248\n",
            "Epoch 384/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1453 - d_loss: 0.5330\n",
            "Epoch 385/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0711 - d_loss: 0.5509\n",
            "Epoch 386/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1047 - d_loss: 0.5594\n",
            "Epoch 387/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1105 - d_loss: 0.5594\n",
            "Epoch 388/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0800 - d_loss: 0.5337\n",
            "Epoch 389/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1409 - d_loss: 0.5511\n",
            "Epoch 390/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1219 - d_loss: 0.5233\n",
            "Epoch 391/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0561 - d_loss: 0.5616\n",
            "Epoch 392/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1701 - d_loss: 0.5432\n",
            "Epoch 393/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1211 - d_loss: 0.5338\n",
            "Epoch 394/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1426 - d_loss: 0.5361\n",
            "Epoch 395/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1250 - d_loss: 0.5260\n",
            "Epoch 396/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.0942 - d_loss: 0.5454\n",
            "Epoch 397/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1244 - d_loss: 0.5314\n",
            "Epoch 398/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1403 - d_loss: 0.5469\n",
            "Epoch 399/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1701 - d_loss: 0.5222\n",
            "Epoch 400/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1163 - d_loss: 0.5456\n",
            "Epoch 401/600\n",
            "110/110 [==============================] - 10s 87ms/step - g_loss: 1.1677 - d_loss: 0.5292\n",
            "Epoch 402/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1475 - d_loss: 0.5532\n",
            "Epoch 403/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1142 - d_loss: 0.5364\n",
            "Epoch 404/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1197 - d_loss: 0.5312\n",
            "Epoch 405/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1035 - d_loss: 0.5217\n",
            "Epoch 406/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1088 - d_loss: 0.5564\n",
            "Epoch 407/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0551 - d_loss: 0.5374\n",
            "Epoch 408/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.1125 - d_loss: 0.5274\n",
            "Epoch 409/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1604 - d_loss: 0.5161\n",
            "Epoch 410/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.2310 - d_loss: 0.5175\n",
            "Epoch 411/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1105 - d_loss: 0.5270\n",
            "Epoch 412/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1092 - d_loss: 0.5398\n",
            "Epoch 413/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.2044 - d_loss: 0.5111\n",
            "Epoch 414/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1491 - d_loss: 0.5106\n",
            "Epoch 415/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1386 - d_loss: 0.5261\n",
            "Epoch 416/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1263 - d_loss: 0.5417\n",
            "Epoch 417/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1711 - d_loss: 0.5452\n",
            "Epoch 418/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.2010 - d_loss: 0.5330\n",
            "Epoch 419/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1164 - d_loss: 0.5515\n",
            "Epoch 420/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.2349 - d_loss: 0.5105\n",
            "Epoch 421/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1589 - d_loss: 0.5244\n",
            "Epoch 422/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1050 - d_loss: 0.5193\n",
            "Epoch 423/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.1606 - d_loss: 0.5218\n",
            "Epoch 424/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.0952 - d_loss: 0.5408\n",
            "Epoch 425/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4920 - d_loss: 0.4197\n",
            "Epoch 426/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.9681 - d_loss: 0.3491\n",
            "Epoch 427/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.8089 - d_loss: 0.3689\n",
            "Epoch 428/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 2.0178 - d_loss: 0.3074\n",
            "Epoch 429/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.7227 - d_loss: 0.3406\n",
            "Epoch 430/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.6133 - d_loss: 0.3509\n",
            "Epoch 431/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5315 - d_loss: 0.3619\n",
            "Epoch 432/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5855 - d_loss: 0.3709\n",
            "Epoch 433/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4935 - d_loss: 0.3829\n",
            "Epoch 434/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5512 - d_loss: 0.3901\n",
            "Epoch 435/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4429 - d_loss: 0.3881\n",
            "Epoch 436/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4957 - d_loss: 0.3883\n",
            "Epoch 437/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4786 - d_loss: 0.3922\n",
            "Epoch 438/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5038 - d_loss: 0.3981\n",
            "Epoch 439/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5061 - d_loss: 0.4015\n",
            "Epoch 440/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.7349 - d_loss: 0.3988\n",
            "Epoch 441/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4901 - d_loss: 0.3976\n",
            "Epoch 442/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5198 - d_loss: 0.3910\n",
            "Epoch 443/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4497 - d_loss: 0.4048\n",
            "Epoch 444/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4506 - d_loss: 0.4023\n",
            "Epoch 445/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4869 - d_loss: 0.3998\n",
            "Epoch 446/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5010 - d_loss: 0.4067\n",
            "Epoch 447/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5512 - d_loss: 0.4002\n",
            "Epoch 448/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.7949 - d_loss: 0.3764\n",
            "Epoch 449/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 2.9785 - d_loss: 0.3432\n",
            "Epoch 450/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 2.4396 - d_loss: 0.2690\n",
            "Epoch 451/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 2.4647 - d_loss: 0.2710\n",
            "Epoch 452/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 3.3500 - d_loss: 0.2416\n",
            "Epoch 453/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.9998 - d_loss: 0.2940\n",
            "Epoch 454/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.9450 - d_loss: 0.2800\n",
            "Epoch 455/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.8094 - d_loss: 0.2883\n",
            "Epoch 456/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6806 - d_loss: 0.3111\n",
            "Epoch 457/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6612 - d_loss: 0.3302\n",
            "Epoch 458/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6216 - d_loss: 0.3311\n",
            "Epoch 459/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6890 - d_loss: 0.3271\n",
            "Epoch 460/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6714 - d_loss: 0.3425\n",
            "Epoch 461/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6387 - d_loss: 0.3527\n",
            "Epoch 462/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.6418 - d_loss: 0.3643\n",
            "Epoch 463/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.6178 - d_loss: 0.3651\n",
            "Epoch 464/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6554 - d_loss: 0.3694\n",
            "Epoch 465/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6071 - d_loss: 0.3647\n",
            "Epoch 466/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5572 - d_loss: 0.3690\n",
            "Epoch 467/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5585 - d_loss: 0.3706\n",
            "Epoch 468/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6403 - d_loss: 0.3846\n",
            "Epoch 469/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6164 - d_loss: 0.3751\n",
            "Epoch 470/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.6275 - d_loss: 0.3773\n",
            "Epoch 471/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6928 - d_loss: 0.3769\n",
            "Epoch 472/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6521 - d_loss: 0.3797\n",
            "Epoch 473/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6548 - d_loss: 0.3782\n",
            "Epoch 474/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6938 - d_loss: 0.3654\n",
            "Epoch 475/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5917 - d_loss: 0.3946\n",
            "Epoch 476/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6913 - d_loss: 0.4113\n",
            "Epoch 477/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6476 - d_loss: 0.3877\n",
            "Epoch 478/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6001 - d_loss: 0.3862\n",
            "Epoch 479/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5672 - d_loss: 0.3944\n",
            "Epoch 480/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5272 - d_loss: 0.3916\n",
            "Epoch 481/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5254 - d_loss: 0.3997\n",
            "Epoch 482/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4906 - d_loss: 0.3987\n",
            "Epoch 483/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6064 - d_loss: 0.3841\n",
            "Epoch 484/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5000 - d_loss: 0.4042\n",
            "Epoch 485/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4913 - d_loss: 0.4131\n",
            "Epoch 486/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4476 - d_loss: 0.4012\n",
            "Epoch 487/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5038 - d_loss: 0.4172\n",
            "Epoch 488/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5048 - d_loss: 0.4192\n",
            "Epoch 489/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5243 - d_loss: 0.4123\n",
            "Epoch 490/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6013 - d_loss: 0.4011\n",
            "Epoch 491/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4863 - d_loss: 0.4057\n",
            "Epoch 492/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4635 - d_loss: 0.4190\n",
            "Epoch 493/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4861 - d_loss: 0.4170\n",
            "Epoch 494/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5149 - d_loss: 0.4199\n",
            "Epoch 495/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4371 - d_loss: 0.4240\n",
            "Epoch 496/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4452 - d_loss: 0.4197\n",
            "Epoch 497/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4519 - d_loss: 0.4279\n",
            "Epoch 498/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4601 - d_loss: 0.4149\n",
            "Epoch 499/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4734 - d_loss: 0.4219\n",
            "Epoch 500/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4361 - d_loss: 0.4183\n",
            "Epoch 501/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4785 - d_loss: 0.4136\n",
            "Epoch 502/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5671 - d_loss: 0.4097\n",
            "Epoch 503/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4234 - d_loss: 0.4119\n",
            "Epoch 504/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6555 - d_loss: 0.3780\n",
            "Epoch 505/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5042 - d_loss: 0.4019\n",
            "Epoch 506/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5246 - d_loss: 0.3984\n",
            "Epoch 507/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4967 - d_loss: 0.3942\n",
            "Epoch 508/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4936 - d_loss: 0.4109\n",
            "Epoch 509/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4663 - d_loss: 0.4097\n",
            "Epoch 510/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4721 - d_loss: 0.4105\n",
            "Epoch 511/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4448 - d_loss: 0.4134\n",
            "Epoch 512/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4610 - d_loss: 0.4137\n",
            "Epoch 513/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4456 - d_loss: 0.4133\n",
            "Epoch 514/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4690 - d_loss: 0.4042\n",
            "Epoch 515/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4848 - d_loss: 0.4077\n",
            "Epoch 516/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4191 - d_loss: 0.4140\n",
            "Epoch 517/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4641 - d_loss: 0.4107\n",
            "Epoch 518/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5244 - d_loss: 0.4191\n",
            "Epoch 519/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4521 - d_loss: 0.4123\n",
            "Epoch 520/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4644 - d_loss: 0.4187\n",
            "Epoch 521/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4603 - d_loss: 0.4081\n",
            "Epoch 522/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4683 - d_loss: 0.4134\n",
            "Epoch 523/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4258 - d_loss: 0.4166\n",
            "Epoch 524/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4771 - d_loss: 0.4174\n",
            "Epoch 525/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4577 - d_loss: 0.4216\n",
            "Epoch 526/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4543 - d_loss: 0.4036\n",
            "Epoch 527/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4619 - d_loss: 0.4042\n",
            "Epoch 528/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4618 - d_loss: 0.4149\n",
            "Epoch 529/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4800 - d_loss: 0.4005\n",
            "Epoch 530/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4219 - d_loss: 0.4161\n",
            "Epoch 531/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4439 - d_loss: 0.4134\n",
            "Epoch 532/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4662 - d_loss: 0.4076\n",
            "Epoch 533/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4515 - d_loss: 0.4034\n",
            "Epoch 534/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4455 - d_loss: 0.4131\n",
            "Epoch 535/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5036 - d_loss: 0.4091\n",
            "Epoch 536/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4535 - d_loss: 0.4115\n",
            "Epoch 537/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4932 - d_loss: 0.4111\n",
            "Epoch 538/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4575 - d_loss: 0.4125\n",
            "Epoch 539/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4774 - d_loss: 0.4167\n",
            "Epoch 540/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6034 - d_loss: 0.4067\n",
            "Epoch 541/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4460 - d_loss: 0.4358\n",
            "Epoch 542/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4805 - d_loss: 0.4054\n",
            "Epoch 543/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4340 - d_loss: 0.4319\n",
            "Epoch 544/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4705 - d_loss: 0.4119\n",
            "Epoch 545/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5491 - d_loss: 0.3962\n",
            "Epoch 546/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5319 - d_loss: 0.3970\n",
            "Epoch 547/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5272 - d_loss: 0.3909\n",
            "Epoch 548/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4844 - d_loss: 0.4085\n",
            "Epoch 549/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4327 - d_loss: 0.4295\n",
            "Epoch 550/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4407 - d_loss: 0.4218\n",
            "Epoch 551/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4812 - d_loss: 0.4129\n",
            "Epoch 552/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4759 - d_loss: 0.4016\n",
            "Epoch 553/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4586 - d_loss: 0.4232\n",
            "Epoch 554/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4031 - d_loss: 0.4217\n",
            "Epoch 555/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4898 - d_loss: 0.4331\n",
            "Epoch 556/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5106 - d_loss: 0.4208\n",
            "Epoch 557/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5084 - d_loss: 0.4149\n",
            "Epoch 558/600\n",
            "110/110 [==============================] - 10s 95ms/step - g_loss: 1.5130 - d_loss: 0.4173\n",
            "Epoch 559/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4733 - d_loss: 0.4211\n",
            "Epoch 560/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4157 - d_loss: 0.4363\n",
            "Epoch 561/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4431 - d_loss: 0.4302\n",
            "Epoch 562/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5240 - d_loss: 0.4174\n",
            "Epoch 563/600\n",
            "110/110 [==============================] - 10s 87ms/step - g_loss: 1.5500 - d_loss: 0.3977\n",
            "Epoch 564/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4405 - d_loss: 0.4133\n",
            "Epoch 565/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4501 - d_loss: 0.4293\n",
            "Epoch 566/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4855 - d_loss: 0.4148\n",
            "Epoch 567/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4562 - d_loss: 0.4268\n",
            "Epoch 568/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4083 - d_loss: 0.4473\n",
            "Epoch 569/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5553 - d_loss: 0.4122\n",
            "Epoch 570/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4594 - d_loss: 0.4196\n",
            "Epoch 571/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4694 - d_loss: 0.4129\n",
            "Epoch 572/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4786 - d_loss: 0.4169\n",
            "Epoch 573/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4906 - d_loss: 0.4189\n",
            "Epoch 574/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5056 - d_loss: 0.4147\n",
            "Epoch 575/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5877 - d_loss: 0.3908\n",
            "Epoch 576/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5336 - d_loss: 0.4291\n",
            "Epoch 577/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4670 - d_loss: 0.4277\n",
            "Epoch 578/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4313 - d_loss: 0.4381\n",
            "Epoch 579/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4272 - d_loss: 0.4404\n",
            "Epoch 580/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4551 - d_loss: 0.4072\n",
            "Epoch 581/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4290 - d_loss: 0.4317\n",
            "Epoch 582/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4820 - d_loss: 0.4117\n",
            "Epoch 583/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4646 - d_loss: 0.4231\n",
            "Epoch 584/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4163 - d_loss: 0.4456\n",
            "Epoch 585/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.3985 - d_loss: 0.4329\n",
            "Epoch 586/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4854 - d_loss: 0.4260\n",
            "Epoch 587/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4436 - d_loss: 0.4333\n",
            "Epoch 588/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4140 - d_loss: 0.4382\n",
            "Epoch 589/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4687 - d_loss: 0.4350\n",
            "Epoch 590/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4515 - d_loss: 0.4266\n",
            "Epoch 591/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4601 - d_loss: 0.4293\n",
            "Epoch 592/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4427 - d_loss: 0.4238\n",
            "Epoch 593/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4427 - d_loss: 0.4208\n",
            "Epoch 594/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4210 - d_loss: 0.4267\n",
            "Epoch 595/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4678 - d_loss: 0.4199\n",
            "Epoch 596/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4326 - d_loss: 0.4401\n",
            "Epoch 597/600\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.4049 - d_loss: 0.4371\n",
            "Epoch 598/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4563 - d_loss: 0.4346\n",
            "Epoch 599/600\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5154 - d_loss: 0.4062\n",
            "Epoch 600/600\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4924 - d_loss: 0.4565\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbfa196cf10>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cond_gan.fit(dataset, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGCQvfyRcgWx",
        "outputId": "aa4bbc6b-b6f9-4dc2-c17e-ff95ba01d7de"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4220 - d_loss: 0.4401\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.5015 - d_loss: 0.4063\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.4506 - d_loss: 0.4459\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.4840 - d_loss: 0.4169\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.4991 - d_loss: 0.4188\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.4407 - d_loss: 0.4210\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.5199 - d_loss: 0.4045\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.5112 - d_loss: 0.4070\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.5222 - d_loss: 0.4113\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.5849 - d_loss: 0.4190\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.4371 - d_loss: 0.4283\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.5144 - d_loss: 0.4145\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.6655 - d_loss: 0.4013\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.5223 - d_loss: 0.3982\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.4800 - d_loss: 0.4195\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.6236 - d_loss: 0.3878\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4586 - d_loss: 0.4464\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5741 - d_loss: 0.4169\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4508 - d_loss: 0.4170\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4188 - d_loss: 0.4520\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4623 - d_loss: 0.4330\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5785 - d_loss: 0.4086\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.3922 - d_loss: 0.4565\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4896 - d_loss: 0.4374\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4625 - d_loss: 0.4357\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4298 - d_loss: 0.4566\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5061 - d_loss: 0.4209\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5223 - d_loss: 0.4169\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4606 - d_loss: 0.4199\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4684 - d_loss: 0.4282\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4357 - d_loss: 0.4295\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5006 - d_loss: 0.4290\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4505 - d_loss: 0.4530\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5107 - d_loss: 0.4129\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5386 - d_loss: 0.4257\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4527 - d_loss: 0.4404\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4597 - d_loss: 0.4470\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4924 - d_loss: 0.4211\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4584 - d_loss: 0.4352\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4653 - d_loss: 0.4369\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4199 - d_loss: 0.4467\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4280 - d_loss: 0.4608\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.4781 - d_loss: 0.4215\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4202 - d_loss: 0.4527\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5200 - d_loss: 0.4356\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5469 - d_loss: 0.4154\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5611 - d_loss: 0.4402\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4389 - d_loss: 0.4471\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4208 - d_loss: 0.4313\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4902 - d_loss: 0.4139\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4800 - d_loss: 0.4204\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4489 - d_loss: 0.4605\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6013 - d_loss: 0.3858\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4644 - d_loss: 0.4368\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.4793 - d_loss: 0.4173\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4260 - d_loss: 0.4400\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4405 - d_loss: 0.4468\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5251 - d_loss: 0.4146\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5502 - d_loss: 0.4217\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4376 - d_loss: 0.4568\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5267 - d_loss: 0.4349\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 10s 90ms/step - g_loss: 1.4720 - d_loss: 0.4363\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4899 - d_loss: 0.4332\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4372 - d_loss: 0.4414\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5108 - d_loss: 0.4334\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4063 - d_loss: 0.4384\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5595 - d_loss: 0.3982\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 9s 86ms/step - g_loss: 1.5228 - d_loss: 0.4186\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5473 - d_loss: 0.4108\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4486 - d_loss: 0.4379\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5047 - d_loss: 0.4337\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5401 - d_loss: 0.4109\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5098 - d_loss: 0.4291\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5437 - d_loss: 0.4326\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4826 - d_loss: 0.4252\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5482 - d_loss: 0.4083\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4931 - d_loss: 0.4207\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4978 - d_loss: 0.4134\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.5047 - d_loss: 0.4459\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5862 - d_loss: 0.3939\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5612 - d_loss: 0.4172\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4649 - d_loss: 0.4388\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5781 - d_loss: 0.4026\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4989 - d_loss: 0.4564\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.5395 - d_loss: 0.4397\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5018 - d_loss: 0.4060\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4634 - d_loss: 0.4359\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5643 - d_loss: 0.4047\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4880 - d_loss: 0.4423\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4149 - d_loss: 0.4326\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5822 - d_loss: 0.3925\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4607 - d_loss: 0.4254\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5440 - d_loss: 0.4167\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.4060 - d_loss: 0.4497\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 2.1817 - d_loss: 0.2368\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7818 - d_loss: 0.3157\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.7508 - d_loss: 0.3233\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7190 - d_loss: 0.3366\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7196 - d_loss: 0.3414\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7425 - d_loss: 0.3375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbfa19282b0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cond_gan.fit(dataset, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhn0bgBSgb_U",
        "outputId": "2d95d968-5cb0-4d12-d29e-a090c78b4f66"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.6925 - d_loss: 0.3451\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.6813 - d_loss: 0.3563\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.7518 - d_loss: 0.3935\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.9481 - d_loss: 0.3045\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 9s 81ms/step - g_loss: 1.7695 - d_loss: 0.3393\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6768 - d_loss: 0.3372\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.7191 - d_loss: 0.3403\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.7067 - d_loss: 0.3460\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.7388 - d_loss: 0.3340\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.7078 - d_loss: 0.3513\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 9s 82ms/step - g_loss: 1.7099 - d_loss: 0.3520\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6663 - d_loss: 0.3466\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6951 - d_loss: 0.3515\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.7256 - d_loss: 0.3409\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.8278 - d_loss: 0.3500\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7246 - d_loss: 0.3546\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6585 - d_loss: 0.3956\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6350 - d_loss: 0.3695\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.7041 - d_loss: 0.3840\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5748 - d_loss: 0.4112\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6775 - d_loss: 0.3722\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7471 - d_loss: 0.3392\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7586 - d_loss: 0.3363\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6641 - d_loss: 0.3667\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6169 - d_loss: 0.3778\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6809 - d_loss: 0.3662\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6306 - d_loss: 0.3890\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7053 - d_loss: 0.3857\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6360 - d_loss: 0.4135\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6244 - d_loss: 0.3841\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6584 - d_loss: 0.3956\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6681 - d_loss: 0.3976\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7273 - d_loss: 0.3790\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6328 - d_loss: 0.4119\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5964 - d_loss: 0.3840\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6843 - d_loss: 0.3943\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6760 - d_loss: 0.3682\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6002 - d_loss: 0.3859\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6095 - d_loss: 0.3963\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6589 - d_loss: 0.3831\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7364 - d_loss: 0.3623\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7029 - d_loss: 0.3603\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6958 - d_loss: 0.3924\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6419 - d_loss: 0.3997\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6731 - d_loss: 0.3924\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5930 - d_loss: 0.4135\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6750 - d_loss: 0.3629\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6580 - d_loss: 0.3798\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6452 - d_loss: 0.3952\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6625 - d_loss: 0.3765\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6589 - d_loss: 0.3979\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6217 - d_loss: 0.3745\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6118 - d_loss: 0.3848\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7111 - d_loss: 0.3617\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.8323 - d_loss: 0.3593\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5957 - d_loss: 0.3880\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7272 - d_loss: 0.3780\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7031 - d_loss: 0.3855\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7078 - d_loss: 0.3602\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6652 - d_loss: 0.3758\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6618 - d_loss: 0.3757\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6580 - d_loss: 0.3962\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6745 - d_loss: 0.3769\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6224 - d_loss: 0.3858\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6010 - d_loss: 0.3979\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6555 - d_loss: 0.3972\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6320 - d_loss: 0.4080\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6724 - d_loss: 0.4743\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7150 - d_loss: 0.3819\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7518 - d_loss: 0.3855\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6070 - d_loss: 0.4058\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6190 - d_loss: 0.3978\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5974 - d_loss: 0.3900\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6487 - d_loss: 0.3991\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 9s 83ms/step - g_loss: 1.6640 - d_loss: 0.3904\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6825 - d_loss: 0.3464\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5820 - d_loss: 0.4156\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5903 - d_loss: 0.3938\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6183 - d_loss: 0.3901\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5773 - d_loss: 0.3954\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7673 - d_loss: 0.3647\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6564 - d_loss: 0.4006\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6202 - d_loss: 0.3637\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6411 - d_loss: 0.3930\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7162 - d_loss: 0.3845\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6694 - d_loss: 0.3579\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6230 - d_loss: 0.4045\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6382 - d_loss: 0.3886\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7527 - d_loss: 0.3554\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6884 - d_loss: 0.3892\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6134 - d_loss: 0.4123\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.8125 - d_loss: 0.3577\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7306 - d_loss: 0.3678\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7172 - d_loss: 0.3750\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.5929 - d_loss: 0.3921\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 9s 85ms/step - g_loss: 1.6793 - d_loss: 0.3670\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7908 - d_loss: 0.3503\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6956 - d_loss: 0.3794\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.6558 - d_loss: 0.3802\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 9s 84ms/step - g_loss: 1.7432 - d_loss: 0.3649\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbfa2db4040>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We first extract the trained generator from our Conditiona GAN.\n",
        "trained_gen = cond_gan.generator\n",
        "\n",
        "# Choose the number of intermediate images that would be generated in\n",
        "# between the interpolation + 2 (start and last images).\n",
        "num_interpolation = 3  # @param {type:\"integer\"}\n",
        "\n",
        "# Sample noise for the interpolation.\n",
        "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
        "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
        "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
        "\n",
        "\n",
        "def interpolate_class(first_number, second_number):\n",
        "    # Convert the start and end labels to one-hot encoded vectors.\n",
        "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
        "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
        "    first_label = tf.cast(first_label, tf.float32)\n",
        "    second_label = tf.cast(second_label, tf.float32)\n",
        "\n",
        "    # Calculate the interpolation vector between the two labels.\n",
        "    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
        "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
        "    interpolation_labels = (\n",
        "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
        "    )\n",
        "\n",
        "    # Combine the noise and the labels and run inference with the generator.\n",
        "    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
        "    fake = trained_gen.predict(noise_and_labels)\n",
        "    return fake\n",
        "\n",
        "\n",
        "start_class = 0  # @param {type:\"slider\", min:0, max:4, step:1}\n",
        "end_class = 3  # @param {type:\"slider\", min:0, max:4, step:1}\n",
        "\n",
        "fake_images = interpolate_class(start_class, end_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbTVrcmvaQBi",
        "outputId": "81ccfc91-843c-46ac-aca4-6a0449734423"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_gen.save(\"brain_gen.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbKBJOoFmJsa",
        "outputId": "0aa114e1-e1f3-43d0-f568-4712c069acf1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_images *= 255.0\n",
        "converted_images = fake_images.astype(np.uint8)\n",
        "converted_images = tf.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n",
        "imageio.mimsave(\"animation.gif\", converted_images, fps=1)\n",
        "embed.embed_file(\"animation.gif\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "XH3dwKKRakR3",
        "outputId": "77ef9fcc-89cf-48f2-a02f-96e7062c33ce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"data:image/gif;base64,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\"/>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}